23 October 2022
Python Pandas Free Interview Test

_______________________________________________________________________________________________________________________________________________________________________

# Find the titles of workers that earn the highest salary. Output the highest-paid title or multiple titles that share the highest salary.

# Import your libraries
import pandas as pd

# Start writing code
merged_df = worker.merge(title, how='left', left_on = 'worker_id', right_on = 'worker_ref_id')
merged_df = merged_df[['worker_title', 'salary']]
output = merged_df[merged_df['salary'] == merged_df['salary'].max()]
output['worker_title'] 

--> SOLVED.

_______________________________________________________________________________________________________________________________________________________________________

# You're given a dataset of health inspections. Count the number of violation in an inspection in 'Roxanne Cafe' for each year. 
# If an inspection resulted in a violation, there will be a value in the 'violation_id' column. Output the number of violations by year in ascending order.

# Import your libraries
import pandas as pd

# Start writing code
sf_restaurant_keycolumns = sf_restaurant_health_violations[['business_name' , 'inspection_date', 'violation_id']]
roxanne_cafe_df =  sf_restaurant_keycolumns[sf_restaurant_keycolumns['business_name'].str.lower().str.contains("roxanne cafe")]
roxanne_cafe_df['inspection_year'] = pd.to_datetime(roxanne_cafe_df['inspection_date']).dt.year
roxanne_cafe_df.groupby(['inspection_year'])['violation_id'].count().reset_index()

--> SOLVED.

_______________________________________________________________________________________________________________________________________________________________________


# Calculate each user's average session time. A session is defined as the time difference between a page_load and page_exit. 
# For simplicity, assume a user has only 1 session per day and if there are multiple of the same events on that day, 
# consider only the latest page_load and earliest page_exit. Output the user_id and their average session time.

# Import your libraries
import pandas as pd
import numpy as np

# Start writing code
# facebook_web_log.head()

fwl = facebook_web_log

# Split page_load and page_exit into two different columns and merge it using on 'user_id' variables.
# Uses dropna function to remove rows that does not meet this conditions (consider only latest page_load and earliest page_exit)

df = pd.merge(fwl.loc[fwl['action'] == 'page_load', ['user_id', 'timestamp']], 
              fwl.loc[fwl['action'] == 'page_exit', ['user_id', 'timestamp']], 
              how = 'left', on = 'user_id', suffixes = ['_load', '_exit']).dropna()
              

# Create Date columns for groubyby function

df['date_load'] = df['timestamp_load'].dt.date
df = df[df['timestamp_load'] < df['timestamp_exit']]

# Agg fuction to call out only max timestamp load and min timestamp exit

df = df.groupby(['user_id', 'date_load']).agg({'timestamp_load': 'max', 'timestamp_exit': 'min'}).reset_index()

# Create column to calculate duration each day

df['duration'] = df['timestamp_exit'] - df['timestamp_load']

# Groupby users to calculate user average duration by users, using agg function to calculate mean

result = df.groupby(['user_id'])['duration'].agg(lambda x: np.mean(x)).reset_index()



